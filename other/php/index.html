<P>
那么怎么在自己电脑上轻松方便地运行这些大模型呢？一般来说，运行这些模型的 Python / PyTorch 往往包含有 3GB 以上的相互依赖的包。即使设法安装了这些包，也总会与你的 GPU 或其他硬件加速器不兼容，导致非常糟糕的性能。

其实大可不必这样艰难！我们可以使用 Rust 和 WasmEdge，在本地创建和部署非常快速和轻量级的 LLM 推理应用。安装文件也非常小，是一个只有几 MB 的简单二进制可执行文件。更赞的是，这个负责推理的应用程序完全可以跨广泛的 CPU、GPU 和操作系统移植。最赞的是，它完全没有 Python 依赖。让我们开始吧！
那么怎么在自己电脑上轻松方便地运行这些大模型呢？一般来说，运行这些模型的 Python / PyTorch 往往包含有 3GB 以上的相互依赖的包。即使设法安装了这些包，也总会与你的 GPU 或其他硬件加速器不兼容，导致非常糟糕的性能。  
</P>
